

x-airflow-common: &airflow-common
  image: apache/airflow:2.5.0-python3.10
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    _PIP_ADDITIONAL_REQUIREMENTS: apache-airflow-providers-postgres apache-airflow-providers-apache-spark pyspark kafka-python polygon-api-client psycopg2-binary
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./spark_apps:/opt/spark/apps
  user: "${AIRFLOW_UID:-50000}:0"

services:
  # Spark Master
  spark-master:
    container_name: fininsights-spark-master
    build: ./spark
    image: spark:latest
    entrypoint: ['/opt/entrypoint.sh', 'master']    
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    volumes:
      - ./spark_apps:/opt/spark/apps
      - ./data:/opt/spark/data
      - spark-logs:/opt/spark/spark-events
    ports:
      - "9090:8080"  # Spark UI
      - "7077:7077"  # Spark Master

  # Spark Workers (3 for 3GB capacity)
  spark-worker:
    image: spark:latest
    entrypoint: ['/opt/entrypoint.sh', 'worker']    
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
    volumes:
      - ./spark_apps:/opt/spark/apps
      - ./data:/opt/spark/data
    deploy:
      replicas: 3

  # PostgreSQL (Airflow + Financial Data)
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init-databases.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 10s
      retries: 5

  # Kafka  -- using KRaft mode
  kafka:
    image: 'bitnami/kafka:3.4.0'
    container_name: fininsights-kafka  
    environment:
      # KRaft Configuration
      KAFKA_ENABLE_KRAFT: yes
      KAFKA_CFG_PROCESS_ROLES: broker,controller
      KAFKA_CFG_NODE_ID: 1
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      
      # Listener Configuration 
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      
      # Inter-broker communication
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      
      # Topic Configuration
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      
      # Performance & Retention 
      KAFKA_LOG_RETENTION_HOURS: 168  # 7 days - matches cleanup policy
      KAFKA_LOG_SEGMENT_BYTES: 536870912  # 512MB (better for volume)
      KAFKA_MESSAGE_MAX_BYTES: 10485760  # 10MB - good for OHLC data
      KAFKA_REPLICA_FETCH_MAX_BYTES: 10485760
      
      # Memory & Performance
      KAFKA_HEAP_OPTS: "-Xmx512m -Xms512m"
      KAFKA_CFG_NUM_PARTITIONS: 2  # Better for parallelism
      
      # Security
      ALLOW_PLAINTEXT_LISTENER: yes
      
      # Debugging (disable in production)
      BITNAMI_DEBUG: no  # Change to 'no' for production
      
    ports:
      - "9092:9092"  # Internal/Docker communication
      - "9094:9094"  # External access from host
    
      
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 3
    
    restart: unless-stopped

   # Kafka Topic Initialization 
  kafka-init:
  image: 'bitnami/kafka:3.4.0'
  depends_on:
    - kafka
  entrypoint: ['/bin/sh', '-c']
  command: |
    "
    # Wait for Kafka to be ready
    until kafka-topics.sh --bootstrap-server kafka:9092 --list; do
      echo 'Waiting for Kafka to be ready...'
      sleep 2
    done
    
    # Create financial_ohlc topic if it doesn't exist
    kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists \
      --topic financial_ohlc \
      --partitions 2 \
      --replication-factor 1 \
      --config retention.ms=604800000 \
      --config segment.ms=86400000 \
      --config compression.type=gzip
    
    echo 'Topics created successfully'
    "
    
  # Airflow Services
  airflow-db-init:
    <<: *airflow-common
    command: >
      bash -c "
        airflow db init &&
        airflow users create \
          --username admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@fininsights.com \
          --password admin123
      "

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - airflow-db-init
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    depends_on:
      - postgres
      - airflow-db-init
    restart: always

volumes:
  postgres_data:
  spark-logs:
  kafka_data: